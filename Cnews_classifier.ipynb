{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow.contrib.keras as kr\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取词汇表\n",
    "def read_vocab(vocab_dir):\n",
    "    with open(vocab_dir, 'r', encoding='utf-8', errors='ignore') as fp:\n",
    "        words = [_.strip() for _ in fp.readlines()]\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "    return words, word_to_id\n",
    " \n",
    "# 读取分类目录，固定\n",
    "def read_category():\n",
    "    categories = ['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n",
    "    categories = [x for x in categories]\n",
    "    cat_to_id = dict(zip(categories, range(len(categories)))) \n",
    "    return categories, cat_to_id\n",
    " \n",
    "# 将文件转换为id表示\n",
    "def process_file(filename, word_to_id, cat_to_id, max_length=600):\n",
    "    contents, labels = [], []\n",
    "    with open(filename, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                label, content = line.strip().split('\\t')\n",
    "                if content:\n",
    "                    contents.append(list(content))\n",
    "                    labels.append(label)\n",
    "            except:\n",
    "                pass\n",
    "    data_id, label_id = [], []\n",
    "    for i in range(len(contents)):\n",
    "        data_id.append([word_to_id[x] for x in contents[i] if x in word_to_id])#将每句话id化\n",
    "        label_id.append(cat_to_id[labels[i]])#每句话对应的类别的id\n",
    "    \n",
    "    # # 使用keras提供的pad_sequences来将文本pad为固定长度\n",
    "    x_pad = kr.preprocessing.sequence.pad_sequences(data_id, max_length)\n",
    "    x_pad = torch.LongTensor(x_pad)\n",
    "    y_pad = kr.utils.to_categorical(label_id, num_classes=len(cat_to_id))  # 将标签转换为one-hot表示\n",
    "    \n",
    "    return x_pad, y_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']\n"
     ]
    }
   ],
   "source": [
    "# 获取文本的类别及其对应id的字典\n",
    "categories, cat_to_id = read_category()\n",
    "print(categories)\n",
    "# 获取训练文本中所有出现过的字及其所对应的id\n",
    "words, word_to_id = read_vocab('./dataset/cnews.vocab.txt')\n",
    "#print(words)\n",
    "#print(word_to_id)\n",
    "\n",
    "#获取字数\n",
    "vocab_size = len(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载及分批\n",
    "# 获取训练数据每个字的id和对应标签的one-hot形式\n",
    "x_train, y_train = process_file('./dataset/cnews.train.txt', word_to_id, cat_to_id, 600)\n",
    "# print('x_train=', x_train)\n",
    "x_val, y_val = process_file('./dataset/cnews.val.txt', word_to_id, cat_to_id, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(x_train.shape)\n",
    "# print(len(words))\n",
    "torch.max(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextRNN Model\n",
    "\n",
    " \n",
    "# 文本分类，RNN模型\n",
    "class TextRNN(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(TextRNN, self).__init__()\n",
    "        # 三个待输入的数据\n",
    "        self.embedding = nn.Embedding(5000, 64)  # 进行词嵌入\n",
    "#         self.rnn = nn.LSTM(input_size=64, hidden_size=128, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.rnn = nn.GRU(input_size=64, hidden_size=128, num_layers=2, bidirectional=True, dropout=0.5, batch_first=True)\n",
    "#         self.f1 = nn.Sequential(nn.Linear(256,128),\n",
    "#                                 nn.Dropout(0.8),\n",
    "#                                 nn.ReLU())\n",
    "        self.fc = nn.Sequential(nn.Linear(256,10),\n",
    "                                nn.Softmax())\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x,_ = self.rnn(x)\n",
    "        x = F.dropout(x,p=0.8)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "class textData(Dataset):\n",
    "    \"\"\"\n",
    "        下载数据、初始化数据，都可以在这里完成\n",
    "    \"\"\"\n",
    "    def __init__(self, train=False, val=False):\n",
    "        categories, cat_to_id = read_category()\n",
    "        words, word_to_id = read_vocab('./dataset/cnews.vocab.txt')\n",
    "        if train:\n",
    "            # 数据加载及分批\n",
    "            # 获取训练数据每个字的id和对应标签的one-hot形式\n",
    "            self.data, self.label = process_file('./dataset/cnews.train.txt', word_to_id, cat_to_id, 600)\n",
    "        elif val:\n",
    "            self.data, self.label = process_file('./dataset/cnews.val.txt', word_to_id, cat_to_id, 600)\n",
    "        else:\n",
    "            self.data, self.label = process_file('./dataset/cnews.test.txt', word_to_id, cat_to_id, 600)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zero\\pycharmprojects\\test\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1 loss:0.6674 acc:0.8750 time:205.4436\n",
      "epoch1  val_acc:0.7212\n",
      "best acc: 0.7212 best epoch: 0\n",
      "epoch2 loss:0.6689 acc:0.8750 time:205.3844\n",
      "epoch3 loss:0.6785 acc:0.7500 time:205.4206\n",
      "epoch3  val_acc:0.7326\n",
      "best acc: 0.7326 best epoch: 2\n",
      "epoch4 loss:0.6615 acc:0.9375 time:205.1645\n",
      "epoch5 loss:0.6617 acc:0.9375 time:205.0819\n",
      "epoch5  val_acc:0.8356\n",
      "best acc: 0.8356 best epoch: 4\n",
      "epoch6 loss:0.6677 acc:0.8750 time:204.8641\n",
      "epoch7 loss:0.6563 acc:1.0000 time:204.9196\n",
      "epoch7  val_acc:0.8580\n",
      "best acc: 0.858 best epoch: 6\n",
      "epoch8 loss:0.6552 acc:1.0000 time:204.9671\n",
      "epoch9 loss:0.6648 acc:0.8750 time:205.0412\n",
      "epoch9  val_acc:0.8806\n",
      "best acc: 0.8806 best epoch: 8\n",
      "epoch10 loss:0.6552 acc:1.0000 time:204.5357\n",
      "epoch11 loss:0.6599 acc:0.9375 time:204.5681\n",
      "epoch11  val_acc:0.8928\n",
      "best acc: 0.8928 best epoch: 10\n",
      "epoch12 loss:0.6552 acc:1.0000 time:204.5983\n",
      "epoch13 loss:0.6552 acc:1.0000 time:204.7678\n",
      "epoch13  val_acc:0.8948\n",
      "best acc: 0.8948 best epoch: 12\n",
      "epoch14 loss:0.6552 acc:1.0000 time:204.4635\n",
      "epoch15 loss:0.6578 acc:1.0000 time:204.5105\n",
      "epoch15  val_acc:0.8980\n",
      "best acc: 0.898 best epoch: 14\n",
      "epoch16 loss:0.6552 acc:1.0000 time:204.4043\n",
      "epoch17 loss:0.6552 acc:1.0000 time:204.4849\n",
      "epoch17  val_acc:0.9150\n",
      "best acc: 0.915 best epoch: 16\n",
      "epoch18 loss:0.6552 acc:1.0000 time:204.4520\n",
      "epoch19 loss:0.6670 acc:0.8750 time:204.7148\n",
      "epoch19  val_acc:0.9292\n",
      "best acc: 0.9292 best epoch: 18\n",
      "epoch20 loss:0.6552 acc:1.0000 time:204.9202\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "def evaluate(model, data_loader, test=False):\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    predict_all = np.array([], dtype=int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x, y = data\n",
    "        texts, labels = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(texts)\n",
    "#             loss = F.cross_entropy(outputs, labels)\n",
    "#             loss_total += loss\n",
    "            labels = torch.argmax(labels, 1).cpu().numpy()\n",
    "            predic = torch.argmax(outputs, 1).cpu().numpy()\n",
    "            labels_all = np.append(labels_all, labels)\n",
    "            predict_all = np.append(predict_all, predic)\n",
    "\n",
    "    acc = metrics.accuracy_score(labels_all, predict_all)\n",
    "#     if test:\n",
    "# #         report = metrics.classification_report(labels_all, predict_all, target_names=config.class_list, digits=4)\n",
    "#         confusion = metrics.confusion_matrix(labels_all, predict_all)\n",
    "#         return acc, loss_total / len(data_loader.dataset), report, confusion\n",
    "#     return acc, loss_total / len(data_loader.dataset)\n",
    "    return acc\n",
    "# def evaluate(model, loader):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = len(loader.dataset)\n",
    "#     for x, y in loader:\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             logits = model(x)\n",
    "#             pred = torch.max(F.softmax(logits), 1)[1]\n",
    "#         correct += torch.eq(pred, y).sum().float().item()\n",
    "#     return correct / total\n",
    "\n",
    "\n",
    "EPOCH = 20\n",
    "batch_size = 32\n",
    "train_data = textData(train=True)\n",
    "val_data = textData(val=True)\n",
    "test_data = textData()\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "model = TextRNN()\n",
    "\n",
    "#损失函数:这里用交叉熵\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "#优化器 这里用SGD\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#device : GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "best_acc, best_epoch = 0, 0\n",
    "file_name = 'best_model.pt'\n",
    "\n",
    "# 训练\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        model.train()\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 清空上一轮梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        accuracy = np.mean((torch.argmax(outputs, 1) == torch.argmax(labels, 1)).cpu().numpy())\n",
    "    print('epoch{} loss:{:.4f} acc:{:.4f} time:{:.4f}'.format(epoch+1, loss.item(), accuracy, time.time()-start_time))\n",
    "#     for step,(x_batch,y_batch) in enumerate(val_loader):\n",
    "#         x = x_batch.cuda()\n",
    "#         y = y_batch.cuda()\n",
    "#         out = model(x)\n",
    "#         #计算准确率\n",
    "#         val_accuracy = np.mean((torch.argmax(out, 1) == torch.argmax(y, 1)).cpu().numpy())\n",
    "#         if val_accuracy > best_acc:\n",
    "#             torch.save(model.state_dict(),'model_params.pkl')\n",
    "#             best_acc = val_accuracy\n",
    "#     print(val_accuracy)\n",
    "    if epoch % 2 == 0:\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "        print('epoch{}  val_acc:{:.4f}'.format(epoch+1, val_acc))\n",
    "        if val_acc > best_acc:\n",
    "            best_epoch = epoch\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), file_name)\n",
    "        print('best acc:', best_acc, 'best epoch:', best_epoch)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试文本分类 准确率:95.2900%\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "test_data = textData()\n",
    "test_loader =  DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = TextRNN()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(file_name))\n",
    "model.eval()\n",
    "\n",
    "correct, total = 0, 0\n",
    "\n",
    "for data in test_loader:\n",
    "    text_data, label = data\n",
    "    text_data, label = text_data.to(device), label.to(device)\n",
    "    # 前向传播\n",
    "    out = model(text_data)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    total += label.size(0)\n",
    "    correct += (predicted == torch.argmax(label, 1)).sum().item()\n",
    "\n",
    "#输出识别准确率\n",
    "print('测试文本分类 准确率:{:.4f}%'.format(100.0 * correct / total)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《时光重返四十二难》恶搞唐增取经一款时下最热门的动画人物：猪猪侠，加上创新的故事背景，震撼的操作快感，成就了这部恶搞新作，现正恶搞上市，玩家们抢先赶快体验快感吧。游戏简介：被时光隧道传送到208年的猪猪侠，必须经历六七四十二难的考验，才能借助柯伊诺尔大钻石的力量，开启时光隧道，重返2008年。在迷糊老师、菲菲公主的帮助下，猪猪侠接受了挑战，开始了这段充满了关心和情谊的旅程。    更多精彩震撼感觉，立即下载该款游戏尽情体验吧。玩家交流才是王道，讯易游戏玩家交流中心 QQ群：6306852-----------------生活要有激情，游戏要玩多彩(多彩游戏)。Colourfulgame (多彩游戏)，让你看看快乐游戏的颜色！精品推荐：1：《钟馗传》大战无头关羽，悲壮的剧情伴随各朝英灵反攻地府！2：《中华群英》将和赵云，项羽，岳飞等猛将作战，穿越各朝代抗击日寇。良品推荐：1：《赌王争霸之斗地主》易飞会在四角恋中会选择谁？是否最终成赌神呢？2：勇者后裔和魔王紧缠一起，前代恩怨《圣火伏魔录》将为您揭示一切。  3：颠覆传统概念，恶搞+非主流？！誓必弄死搞残为止《爆笑飞行棋》。4：《中国象棋残局大师》快棋和人机模式让畅快对弈！一切“多彩游戏”资讯，点击Colourfulgame官网http://www.colourfulgame.com一切“多彩游戏”感言，交流Colourfulgame论坛http://121.33.203.124/forum/【客服邮箱】：xunyiwangluo@126.com\">xunyiwangluo@126.com\">xunyiwangluo@126.com【客服热线】：020-87588437 : 游戏\n"
     ]
    }
   ],
   "source": [
    "class RnnModel:\n",
    "    def __init__(self):\n",
    "        self.categories, self.cat_to_id = read_category()\n",
    "        self.words, self.word_to_id = read_vocab('./dataset/cnews.vocab.txt')\n",
    "        self.model = TextRNN()\n",
    "        self.model.load_state_dict(torch.load('best_model.pt'))\n",
    " \n",
    "    def predict(self, message):\n",
    "        content = message\n",
    "        data = [self.word_to_id[x] for x in content if x in self.word_to_id]\n",
    "        data = kr.preprocessing.sequence.pad_sequences([data], 600)\n",
    "        data = torch.LongTensor(data)\n",
    "        y_pred_cls = self.model(data)\n",
    "        class_index = torch.argmax(y_pred_cls[0]).item()\n",
    "        return self.categories[class_index]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    model = RnnModel()\n",
    "    test_demo = ['《时光重返四十二难》恶搞唐增取经一款时下最热门的动画人物：猪猪侠，加上创新的故事背景，震撼的操作快感，成就了这部恶搞新作，现正恶搞上市，玩家们抢先赶快体验快感吧。游戏简介：被时光隧道传送到208年的猪猪侠，必须经历六七四十二难的考验，才能借助柯伊诺尔大钻石的力量，开启时光隧道，重返2008年。在迷糊老师、菲菲公主的帮助下，猪猪侠接受了挑战，开始了这段充满了关心和情谊的旅程。    更多精彩震撼感觉，立即下载该款游戏尽情体验吧。玩家交流才是王道，讯易游戏玩家交流中心 QQ群：6306852-----------------生活要有激情，游戏要玩多彩(多彩游戏)。Colourfulgame (多彩游戏)，让你看看快乐游戏的颜色！精品推荐：1：《钟馗传》大战无头关羽，悲壮的剧情伴随各朝英灵反攻地府！2：《中华群英》将和赵云，项羽，岳飞等猛将作战，穿越各朝代抗击日寇。良品推荐：1：《赌王争霸之斗地主》易飞会在四角恋中会选择谁？是否最终成赌神呢？2：勇者后裔和魔王紧缠一起，前代恩怨《圣火伏魔录》将为您揭示一切。  3：颠覆传统概念，恶搞+非主流？！誓必弄死搞残为止《爆笑飞行棋》。4：《中国象棋残局大师》快棋和人机模式让畅快对弈！一切“多彩游戏”资讯，点击Colourfulgame官网http://www.colourfulgame.com一切“多彩游戏”感言，交流Colourfulgame论坛http://121.33.203.124/forum/【客服邮箱】：xunyiwangluo@126.com\">xunyiwangluo@126.com\">xunyiwangluo@126.com【客服热线】：020-87588437']\n",
    "                 \n",
    "    for i in test_demo:\n",
    "      print(i,\":\",model.predict(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
